{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('EmailsLlm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop uneeded cols and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ilug] stop the mlm insanity</td>\n",
       "      <td>Fri, 02 Aug 2002 23:37:59 0530</td>\n",
       "      <td>greetings! you are receiving this letter becau...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new product announcement</td>\n",
       "      <td>Fri, 3 Jan 1997 17:24:47 -0700</td>\n",
       "      <td>new product announcement from: outsource eng.&amp;...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fw:</td>\n",
       "      <td>Fri, 02 Jan 1998 04:30:44 -0400</td>\n",
       "      <td>thank you for your interest! judgment courses ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[sa] urgent help..............</td>\n",
       "      <td>Mon, 5 Apr 1999 20:38:02 +0100</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>finally collecct your judgment (71733)</td>\n",
       "      <td>Wed, 16 Aug 2000 17:38:13 -0400 (EDT)</td>\n",
       "      <td>yes we do purchase uncollected judicial judgem...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>geocaching.com weekly cache notification</td>\n",
       "      <td>Thu, 12 Sep 2002 19:24:11 -0700</td>\n",
       "      <td>greetings from geocaching.com - recent caches ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>securing multiple virtual hosts</td>\n",
       "      <td>Fri, 13 Sep 2002 16:07:47 -0700</td>\n",
       "      <td>i am trying to secure three of four virtual ho...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>javaserver pages updated</td>\n",
       "      <td>Tue, 17 Sep 2002 17:07:02 -0700</td>\n",
       "      <td>filled with useful examples and the depth, cla...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>linux-announce digest #180</td>\n",
       "      <td>Sat, 7 Sep 2002 22:13:03 EDT</td>\n",
       "      <td>linux-announce digest #180, volume #4 sat, 7 s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>(spam? 08.00) lists.sourceforge.net mailing li...</td>\n",
       "      <td>Tue, 01 Oct 2002 17:08:10 -0700</td>\n",
       "      <td>**********************************************...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3415 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Subject  \\\n",
       "0                          [ilug] stop the mlm insanity   \n",
       "6                              new product announcement   \n",
       "7                                                   fw:   \n",
       "8                        [sa] urgent help..............   \n",
       "10               finally collecct your judgment (71733)   \n",
       "...                                                 ...   \n",
       "4193           geocaching.com weekly cache notification   \n",
       "4194                    securing multiple virtual hosts   \n",
       "4195                           javaserver pages updated   \n",
       "4196                         linux-announce digest #180   \n",
       "4197  (spam? 08.00) lists.sourceforge.net mailing li...   \n",
       "\n",
       "                                       Date  \\\n",
       "0            Fri, 02 Aug 2002 23:37:59 0530   \n",
       "6            Fri, 3 Jan 1997 17:24:47 -0700   \n",
       "7           Fri, 02 Jan 1998 04:30:44 -0400   \n",
       "8            Mon, 5 Apr 1999 20:38:02 +0100   \n",
       "10    Wed, 16 Aug 2000 17:38:13 -0400 (EDT)   \n",
       "...                                     ...   \n",
       "4193        Thu, 12 Sep 2002 19:24:11 -0700   \n",
       "4194        Fri, 13 Sep 2002 16:07:47 -0700   \n",
       "4195        Tue, 17 Sep 2002 17:07:02 -0700   \n",
       "4196           Sat, 7 Sep 2002 22:13:03 EDT   \n",
       "4197        Tue, 01 Oct 2002 17:08:10 -0700   \n",
       "\n",
       "                                                   Body Label  \n",
       "0     greetings! you are receiving this letter becau...  spam  \n",
       "6     new product announcement from: outsource eng.&...  spam  \n",
       "7     thank you for your interest! judgment courses ...  spam  \n",
       "8     ----------------------------------------------...  spam  \n",
       "10    yes we do purchase uncollected judicial judgem...  spam  \n",
       "...                                                 ...   ...  \n",
       "4193  greetings from geocaching.com - recent caches ...   ham  \n",
       "4194  i am trying to secure three of four virtual ho...   ham  \n",
       "4195  filled with useful examples and the depth, cla...   ham  \n",
       "4196  linux-announce digest #180, volume #4 sat, 7 s...   ham  \n",
       "4197  **********************************************...   ham  \n",
       "\n",
       "[3415 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keptFeatures = [\"Subject\",\"Date\",\"Body\",\"Label\"]\n",
    "data = data[keptFeatures]\n",
    "data.dropna(inplace=True,how='any')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def Label_to_int(label):\n",
    "    if label == \"ham\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "data[\"Label\"] = data[\"Label\"].apply(Label_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ilug] stop the mlm insanity</td>\n",
       "      <td>23</td>\n",
       "      <td>greetings! you are receiving this letter becau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new product announcement</td>\n",
       "      <td>17</td>\n",
       "      <td>new product announcement from: outsource eng.&amp;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fw:</td>\n",
       "      <td>4</td>\n",
       "      <td>thank you for your interest! judgment courses ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[sa] urgent help..............</td>\n",
       "      <td>20</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>finally collecct your judgment (71733)</td>\n",
       "      <td>17</td>\n",
       "      <td>yes we do purchase uncollected judicial judgem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>geocaching.com weekly cache notification</td>\n",
       "      <td>19</td>\n",
       "      <td>greetings from geocaching.com - recent caches ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>securing multiple virtual hosts</td>\n",
       "      <td>16</td>\n",
       "      <td>i am trying to secure three of four virtual ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>javaserver pages updated</td>\n",
       "      <td>17</td>\n",
       "      <td>filled with useful examples and the depth, cla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>linux-announce digest #180</td>\n",
       "      <td>22</td>\n",
       "      <td>linux-announce digest #180, volume #4 sat, 7 s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>(spam? 08.00) lists.sourceforge.net mailing li...</td>\n",
       "      <td>17</td>\n",
       "      <td>**********************************************...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3415 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Subject  Date  \\\n",
       "0                          [ilug] stop the mlm insanity    23   \n",
       "6                              new product announcement    17   \n",
       "7                                                   fw:     4   \n",
       "8                        [sa] urgent help..............    20   \n",
       "10               finally collecct your judgment (71733)    17   \n",
       "...                                                 ...   ...   \n",
       "4193           geocaching.com weekly cache notification    19   \n",
       "4194                    securing multiple virtual hosts    16   \n",
       "4195                           javaserver pages updated    17   \n",
       "4196                         linux-announce digest #180    22   \n",
       "4197  (spam? 08.00) lists.sourceforge.net mailing li...    17   \n",
       "\n",
       "                                                   Body  Label  \n",
       "0     greetings! you are receiving this letter becau...      1  \n",
       "6     new product announcement from: outsource eng.&...      1  \n",
       "7     thank you for your interest! judgment courses ...      1  \n",
       "8     ----------------------------------------------...      1  \n",
       "10    yes we do purchase uncollected judicial judgem...      1  \n",
       "...                                                 ...    ...  \n",
       "4193  greetings from geocaching.com - recent caches ...      0  \n",
       "4194  i am trying to secure three of four virtual ho...      0  \n",
       "4195  filled with useful examples and the depth, cla...      0  \n",
       "4196  linux-announce digest #180, volume #4 sat, 7 s...      0  \n",
       "4197  **********************************************...      0  \n",
       "\n",
       "[3415 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Mekki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert/distilbert-base-uncased'\n",
    "\n",
    "# Auto means that the type of model is automatically detected depending on the model name \n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, device_map = 'cuda')\n",
    "#model = transformers.TFAutoModelForSequenceTranslation.from_pretrained(model_name,from_pt=True)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, device_map = 'cuda',truncate_long_texts=True)\n",
    "\n",
    "#pipe = transformers.pipeline('text-classification', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf167eef720b48efa98183a2fac2fb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the text\n",
    "    tokenized_inputs = tokenizer(examples['Body'], padding='max_length', truncation=True)\n",
    "    \n",
    "    # Align labels\n",
    "    labels = examples['Label']\n",
    "    \n",
    "    # Add labels to the tokenized inputs\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_test_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_dataset['train']\n",
    "test_dataset = train_test_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=2,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21ea856514348b4b15a667a6c1f8b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7026, 'grad_norm': 2.180034637451172, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 0.7081, 'grad_norm': 2.9429116249084473, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.03}\n",
      "{'loss': 0.6744, 'grad_norm': 2.742413282394409, 'learning_rate': 3e-06, 'epoch': 0.04}\n",
      "{'loss': 0.6374, 'grad_norm': 2.693326711654663, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.06}\n",
      "{'loss': 0.6077, 'grad_norm': 2.1169025897979736, 'learning_rate': 5e-06, 'epoch': 0.07}\n",
      "{'loss': 0.636, 'grad_norm': 2.579866886138916, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
      "{'loss': 0.5548, 'grad_norm': 3.270555257797241, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 0.52, 'grad_norm': 4.142918586730957, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 0.4627, 'grad_norm': 3.5206491947174072, 'learning_rate': 9e-06, 'epoch': 0.13}\n",
      "{'loss': 0.4869, 'grad_norm': 2.9806301593780518, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 0.4084, 'grad_norm': 3.182164192199707, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.16}\n",
      "{'loss': 0.3341, 'grad_norm': 2.7258594036102295, 'learning_rate': 1.2e-05, 'epoch': 0.18}\n",
      "{'loss': 0.2528, 'grad_norm': 1.3857003450393677, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.19}\n",
      "{'loss': 0.217, 'grad_norm': 2.322455883026123, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1772, 'grad_norm': 0.474987268447876, 'learning_rate': 1.5e-05, 'epoch': 0.22}\n",
      "{'loss': 0.2405, 'grad_norm': 2.2347309589385986, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1932, 'grad_norm': 1.0416789054870605, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0223, 'grad_norm': 0.18295815587043762, 'learning_rate': 1.8e-05, 'epoch': 0.26}\n",
      "{'loss': 0.12, 'grad_norm': 1.1650012731552124, 'learning_rate': 1.9e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1169, 'grad_norm': 0.085548035800457, 'learning_rate': 2e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0305, 'grad_norm': 0.09072728455066681, 'learning_rate': 2.1e-05, 'epoch': 0.31}\n",
      "{'loss': 0.028, 'grad_norm': 0.0737004280090332, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.32}\n",
      "{'loss': 0.5828, 'grad_norm': 49.91195297241211, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.34}\n",
      "{'loss': 0.2111, 'grad_norm': 8.194385528564453, 'learning_rate': 2.4e-05, 'epoch': 0.35}\n",
      "{'loss': 0.1606, 'grad_norm': 0.1837802678346634, 'learning_rate': 2.5e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0582, 'grad_norm': 1.165142297744751, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0041, 'grad_norm': 0.07700304687023163, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0039, 'grad_norm': 0.0372224897146225, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3308, 'grad_norm': 0.07159679383039474, 'learning_rate': 2.9e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1572, 'grad_norm': 0.07705535739660263, 'learning_rate': 3e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0119, 'grad_norm': 0.046760443598032, 'learning_rate': 3.1e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0607, 'grad_norm': 0.03917771205306053, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0028, 'grad_norm': 0.041784413158893585, 'learning_rate': 3.3e-05, 'epoch': 0.48}\n",
      "{'loss': 0.5458, 'grad_norm': 17.4456729888916, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4123, 'grad_norm': 0.597015917301178, 'learning_rate': 3.5e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0794, 'grad_norm': 0.13762211799621582, 'learning_rate': 3.6e-05, 'epoch': 0.53}\n",
      "{'loss': 0.008, 'grad_norm': 0.06986279040575027, 'learning_rate': 3.7e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1206, 'grad_norm': 0.03833072632551193, 'learning_rate': 3.8e-05, 'epoch': 0.56}\n",
      "{'loss': 0.1417, 'grad_norm': 0.029546666890382767, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3701, 'grad_norm': 0.12128616869449615, 'learning_rate': 4e-05, 'epoch': 0.59}\n",
      "{'loss': 0.1603, 'grad_norm': 0.03948225826025009, 'learning_rate': 4.1e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3666, 'grad_norm': 0.0971500426530838, 'learning_rate': 4.2e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0938, 'grad_norm': 21.083669662475586, 'learning_rate': 4.3e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2049, 'grad_norm': 60.180545806884766, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0029, 'grad_norm': 0.04132936894893646, 'learning_rate': 4.5e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0014, 'grad_norm': 0.02441641502082348, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0017, 'grad_norm': 0.02213679440319538, 'learning_rate': 4.7e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0018, 'grad_norm': 0.4874383807182312, 'learning_rate': 4.8e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0068, 'grad_norm': 0.019929369911551476, 'learning_rate': 4.9e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2017, 'grad_norm': 0.05311364680528641, 'learning_rate': 5e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2792, 'grad_norm': 7.538919448852539, 'learning_rate': 4.942263279445728e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0021, 'grad_norm': 0.06498456746339798, 'learning_rate': 4.884526558891455e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1286, 'grad_norm': 0.08316820859909058, 'learning_rate': 4.826789838337183e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2102, 'grad_norm': 0.03937927260994911, 'learning_rate': 4.7690531177829104e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3065, 'grad_norm': 0.14723362028598785, 'learning_rate': 4.711316397228638e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4881, 'grad_norm': 16.312397003173828, 'learning_rate': 4.653579676674365e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0894, 'grad_norm': 0.24056090414524078, 'learning_rate': 4.595842956120093e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0397, 'grad_norm': 0.03235673904418945, 'learning_rate': 4.53810623556582e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3026, 'grad_norm': 0.03372935205698013, 'learning_rate': 4.4803695150115474e-05, 'epoch': 0.86}\n",
      "{'loss': 0.1355, 'grad_norm': 0.025640133768320084, 'learning_rate': 4.422632794457275e-05, 'epoch': 0.88}\n",
      "{'loss': 0.149, 'grad_norm': 6.687188148498535, 'learning_rate': 4.3648960739030025e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0419, 'grad_norm': 3.4482429027557373, 'learning_rate': 4.30715935334873e-05, 'epoch': 0.91}\n",
      "{'loss': 0.1412, 'grad_norm': 0.1073189228773117, 'learning_rate': 4.2494226327944576e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4118, 'grad_norm': 0.06871064752340317, 'learning_rate': 4.1916859122401844e-05, 'epoch': 0.94}\n",
      "{'loss': 0.1413, 'grad_norm': 0.9623371958732605, 'learning_rate': 4.1339491916859126e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0034, 'grad_norm': 0.0334453321993351, 'learning_rate': 4.07621247113164e-05, 'epoch': 0.97}\n",
      "{'loss': 0.1188, 'grad_norm': 0.02062821388244629, 'learning_rate': 4.018475750577367e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0506, 'grad_norm': 62.73545455932617, 'learning_rate': 3.960739030023095e-05, 'epoch': 1.0}\n",
      "{'loss': 0.1166, 'grad_norm': 0.01791415549814701, 'learning_rate': 3.903002309468822e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0561, 'grad_norm': 0.017723122611641884, 'learning_rate': 3.84526558891455e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2444, 'grad_norm': 0.036142874509096146, 'learning_rate': 3.787528868360277e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0134, 'grad_norm': 1.5772343873977661, 'learning_rate': 3.729792147806005e-05, 'epoch': 1.05}\n",
      "{'loss': 0.1637, 'grad_norm': 0.025850310921669006, 'learning_rate': 3.672055427251732e-05, 'epoch': 1.07}\n",
      "{'loss': 0.1223, 'grad_norm': 7.510193347930908, 'learning_rate': 3.61431870669746e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0068, 'grad_norm': 0.047220125794410706, 'learning_rate': 3.556581986143187e-05, 'epoch': 1.1}\n",
      "{'loss': 0.1346, 'grad_norm': 0.007601091172546148, 'learning_rate': 3.498845265588915e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0009, 'grad_norm': 0.031166577711701393, 'learning_rate': 3.441108545034642e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0018, 'grad_norm': 0.016038542613387108, 'learning_rate': 3.38337182448037e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2056, 'grad_norm': 0.02267717756330967, 'learning_rate': 3.325635103926097e-05, 'epoch': 1.16}\n",
      "{'loss': 0.391, 'grad_norm': 0.01977074146270752, 'learning_rate': 3.2678983833718243e-05, 'epoch': 1.17}\n",
      "{'loss': 0.0025, 'grad_norm': 0.0675768256187439, 'learning_rate': 3.2101616628175526e-05, 'epoch': 1.19}\n",
      "{'loss': 0.1974, 'grad_norm': 0.03574828803539276, 'learning_rate': 3.1524249422632794e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0016, 'grad_norm': 0.018618185073137283, 'learning_rate': 3.0946882217090076e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0014, 'grad_norm': 0.025062158703804016, 'learning_rate': 3.0369515011547345e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0069, 'grad_norm': 0.08103752881288528, 'learning_rate': 2.9792147806004624e-05, 'epoch': 1.24}\n",
      "{'loss': 0.001, 'grad_norm': 0.017766565084457397, 'learning_rate': 2.9214780600461896e-05, 'epoch': 1.26}\n",
      "{'loss': 0.1835, 'grad_norm': 0.045275717973709106, 'learning_rate': 2.863741339491917e-05, 'epoch': 1.27}\n",
      "{'loss': 0.1557, 'grad_norm': 0.03951592743396759, 'learning_rate': 2.8060046189376443e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1532, 'grad_norm': 0.014482446014881134, 'learning_rate': 2.7482678983833722e-05, 'epoch': 1.3}\n",
      "{'loss': 0.002, 'grad_norm': 0.4565722644329071, 'learning_rate': 2.6905311778290994e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0017, 'grad_norm': 0.021070219576358795, 'learning_rate': 2.632794457274827e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0009, 'grad_norm': 0.031119028106331825, 'learning_rate': 2.575057736720554e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0012, 'grad_norm': 0.07657817751169205, 'learning_rate': 2.517321016166282e-05, 'epoch': 1.36}\n",
      "{'loss': 0.4524, 'grad_norm': 0.01656370982527733, 'learning_rate': 2.4595842956120095e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0022, 'grad_norm': 0.040783997625112534, 'learning_rate': 2.4018475750577367e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1439, 'grad_norm': 0.03780900686979294, 'learning_rate': 2.3441108545034643e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0019, 'grad_norm': 0.014774931594729424, 'learning_rate': 2.2863741339491918e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0015, 'grad_norm': 0.026390882208943367, 'learning_rate': 2.2286374133949193e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0017, 'grad_norm': 0.043402690440416336, 'learning_rate': 2.1709006928406465e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0014, 'grad_norm': 0.02635682001709938, 'learning_rate': 2.113163972286374e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0011, 'grad_norm': 0.024725403636693954, 'learning_rate': 2.0554272517321016e-05, 'epoch': 1.48}\n",
      "{'loss': 0.001, 'grad_norm': 0.025845443829894066, 'learning_rate': 1.997690531177829e-05, 'epoch': 1.49}\n",
      "{'loss': 0.001, 'grad_norm': 0.007176938466727734, 'learning_rate': 1.9399538106235567e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1177, 'grad_norm': 0.010463694110512733, 'learning_rate': 1.8822170900692842e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0007, 'grad_norm': 0.018754377961158752, 'learning_rate': 1.8244803695150118e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0947, 'grad_norm': 1.0581008195877075, 'learning_rate': 1.7667436489607393e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0659, 'grad_norm': 0.06523805856704712, 'learning_rate': 1.7090069284064665e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0202, 'grad_norm': 15.517671585083008, 'learning_rate': 1.651270207852194e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0013, 'grad_norm': 0.01870403066277504, 'learning_rate': 1.5935334872979216e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0008, 'grad_norm': 0.14114902913570404, 'learning_rate': 1.535796766743649e-05, 'epoch': 1.61}\n",
      "{'loss': 0.083, 'grad_norm': 0.012991433031857014, 'learning_rate': 1.4780600461893765e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0561, 'grad_norm': 0.03645223006606102, 'learning_rate': 1.420323325635104e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0005, 'grad_norm': 0.003976434003561735, 'learning_rate': 1.3625866050808314e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0014, 'grad_norm': 0.009709743782877922, 'learning_rate': 1.304849884526559e-05, 'epoch': 1.67}\n",
      "{'loss': 0.143, 'grad_norm': 0.01129541452974081, 'learning_rate': 1.2471131639722865e-05, 'epoch': 1.68}\n",
      "{'loss': 0.1759, 'grad_norm': 0.21462848782539368, 'learning_rate': 1.189376443418014e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0008, 'grad_norm': 0.0373196043074131, 'learning_rate': 1.1316397228637414e-05, 'epoch': 1.71}\n",
      "{'loss': 0.128, 'grad_norm': 0.02325446531176567, 'learning_rate': 1.0739030023094689e-05, 'epoch': 1.73}\n",
      "{'loss': 0.0006, 'grad_norm': 0.01821744069457054, 'learning_rate': 1.0161662817551963e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0005, 'grad_norm': 0.004789947997778654, 'learning_rate': 9.584295612009238e-06, 'epoch': 1.76}\n",
      "{'loss': 0.0006, 'grad_norm': 0.027011021971702576, 'learning_rate': 9.006928406466514e-06, 'epoch': 1.77}\n",
      "{'loss': 0.0005, 'grad_norm': 0.008640490472316742, 'learning_rate': 8.429561200923789e-06, 'epoch': 1.79}\n",
      "{'loss': 0.0004, 'grad_norm': 0.007179234176874161, 'learning_rate': 7.852193995381063e-06, 'epoch': 1.8}\n",
      "{'loss': 0.0005, 'grad_norm': 0.01589956507086754, 'learning_rate': 7.274826789838338e-06, 'epoch': 1.82}\n",
      "{'loss': 0.0007, 'grad_norm': 0.006282095797359943, 'learning_rate': 6.6974595842956126e-06, 'epoch': 1.83}\n",
      "{'loss': 0.402, 'grad_norm': 0.01074795052409172, 'learning_rate': 6.120092378752887e-06, 'epoch': 1.84}\n",
      "{'loss': 0.1447, 'grad_norm': 0.011671693064272404, 'learning_rate': 5.5427251732101625e-06, 'epoch': 1.86}\n",
      "{'loss': 0.0007, 'grad_norm': 0.009230048395693302, 'learning_rate': 4.965357967667437e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0005, 'grad_norm': 0.012393299490213394, 'learning_rate': 4.3879907621247115e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0008, 'grad_norm': 0.004997951909899712, 'learning_rate': 3.810623556581986e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0005, 'grad_norm': 0.009980130940675735, 'learning_rate': 3.2332563510392614e-06, 'epoch': 1.92}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0135583421215415, 'learning_rate': 2.655889145496536e-06, 'epoch': 1.93}\n",
      "{'loss': 0.1674, 'grad_norm': 0.008591199293732643, 'learning_rate': 2.0785219399538105e-06, 'epoch': 1.95}\n",
      "{'loss': 0.0005, 'grad_norm': 0.006953367497771978, 'learning_rate': 1.5011547344110855e-06, 'epoch': 1.96}\n",
      "{'loss': 0.0008, 'grad_norm': 0.013025526888668537, 'learning_rate': 9.237875288683603e-07, 'epoch': 1.98}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011792262084782124, 'learning_rate': 3.4642032332563515e-07, 'epoch': 1.99}\n",
      "{'train_runtime': 2283.4982, 'train_samples_per_second': 2.393, 'train_steps_per_second': 0.598, 'train_loss': 0.14540701415553406, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1366, training_loss=0.14540701415553406, metrics={'train_runtime': 2283.4982, 'train_samples_per_second': 2.393, 'train_steps_per_second': 0.598, 'total_flos': 723801866256384.0, 'train_loss': 0.14540701415553406, 'epoch': 2.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2b03d998e34828901cde3222d6f6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.07932686060667038,\n",
       " 'eval_runtime': 60.3278,\n",
       " 'eval_samples_per_second': 11.321,\n",
       " 'eval_steps_per_second': 1.426,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"email_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1c113b45b241d7811252b8a2cc1bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(axis=-1)\n",
    "    labels = p.label_ids\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "tunedresults = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nonTrainedModel = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, device_map = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bcfcfa9a3741bd89caa055c84bbd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(axis=-1)\n",
    "    labels = p.label_ids\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=nonTrainedModel,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "results = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the base model wasn't made for text classification that's why the bse results are really low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the non-tuned model:\n",
      "{'eval_loss': 0.7070561051368713, 'eval_model_preparation_time': 0.001, 'eval_accuracy': 0.2342606149341142, 'eval_precision': 0.08478260869565217, 'eval_recall': 0.2765957446808511, 'eval_f1': 0.129783693843594, 'eval_runtime': 86.0916, 'eval_samples_per_second': 7.933, 'eval_steps_per_second': 0.999}\n",
      "Results of the tuned model:\n",
      "{'eval_loss': 0.07932686060667038, 'eval_model_preparation_time': 0.002, 'eval_accuracy': 0.9824304538799414, 'eval_precision': 0.9387755102040817, 'eval_recall': 0.9787234042553191, 'eval_f1': 0.9583333333333334, 'eval_runtime': 100.3388, 'eval_samples_per_second': 6.807, 'eval_steps_per_second': 0.857}\n"
     ]
    }
   ],
   "source": [
    "print(\"Results of the non-tuned model:\")\n",
    "print(results)\n",
    "print(\"Results of the tuned model:\")\n",
    "print(tunedresults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
